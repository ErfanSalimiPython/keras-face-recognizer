{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import mtcnn\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = mtcnn.MTCNN()\n",
    "def get_face(img, box):\n",
    "    x1, y1, width, height = box\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    return face, (x1, y1), (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026C4D840940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "images count: 420\n",
      "['Ahmad-Nourollahi', 'Ali-Gholizadeh', 'Alireza-Beiranvand', 'Alireza-Jahanbakhsh', 'Ehsan-Hajsafi', 'Hamed-Lak', 'Hossein-Hosseini', 'Issa-Alekasir', 'Kamal-Kamyabinia', 'Karim-Ansarifard', 'Kaveh-Rezaei', 'Mehdi-Abdi', 'Mehdi-Shiri', 'Mehdi-Taremi', 'Mehdi-Torabi', 'Milad-Mohammadi', 'Milad-Sarlak', 'Mohammad-Hossein-Kanani-Zadegan', 'Omid-Alishah', 'Omid-Noorafkan', 'Sadegh-Moharrami', 'Saeed-Aghaei', 'Saeed-Ezatolahi', 'Saman-Ghoddos', 'Sardar-Azmoun', 'Seyed-Jalal-Hosseini', 'Shoja-Khalilzadeh', 'Vahid-Amiri']\n"
     ]
    }
   ],
   "source": [
    "# data location\n",
    "data_dir = \"F:/ai/recognition-football-players/data/train_faces\"\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# labels and images lists\n",
    "train_labels = []\n",
    "train_images = []\n",
    "\n",
    "# players name\n",
    "players = os.listdir()\n",
    "\n",
    "# images count\n",
    "images_count = 0\n",
    "\n",
    "# class images count\n",
    "class_image = -1\n",
    "\n",
    "class_name = []\n",
    "\n",
    "for player in players:\n",
    "    class_image += 1\n",
    "    \n",
    "    class_name.append(player)\n",
    "\n",
    "    # change directory\n",
    "    os.chdir(f'{data_dir}/{player}')\n",
    "\n",
    "    # all images for this player\n",
    "    images_= os.listdir()\n",
    "\n",
    "    for img_ in images_:\n",
    "        # split image number and name\n",
    "        num = img_.split('_')[0]\n",
    "        name = player\n",
    "\n",
    "        # load image\n",
    "        image_ = cv2.imread(img_)\n",
    "        img_rgb = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # detect face\n",
    "        image_ = face_detector.detect_faces(img_rgb)\n",
    "        if image_:\n",
    "            res = max(image_, key=lambda b: b['box'][2] * b['box'][3])\n",
    "            face, _, _ = get_face(img_rgb, res['box'])\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "\n",
    "        # add images array to images list\n",
    "        train_images.append(face)\n",
    "    \n",
    "        # images_count = images_count + 1\n",
    "        images_count += 1\n",
    "        \n",
    "        train_labels.append([class_image])\n",
    "\n",
    "# images count\n",
    "print(f'images count: {images_count}')\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels and images lists\n",
    "test_labels = []\n",
    "test_images = []\n",
    "\n",
    "data_dir = \"F:/ai/recognition-football-players/data/test_faces\"\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# players name\n",
    "players = os.listdir()\n",
    "\n",
    "# images count\n",
    "images_count = 0\n",
    "\n",
    "# class images count\n",
    "class_image = -1\n",
    "\n",
    "class_name = []\n",
    "\n",
    "columns = 20\n",
    "rows = 28\n",
    "# fig = plt.figure(figsize=(120, 110))\n",
    "for player in players:\n",
    "    class_image += 1\n",
    "    \n",
    "    class_name.append(player)\n",
    "\n",
    "    # change directory\n",
    "    os.chdir(sys.path[0])\n",
    "    os.chdir(r\"F:\\ai\\recognition-football-players\\data\\test_faces\")\n",
    "    os.chdir(f'./{player}')\n",
    "    \n",
    "    # all images for this player\n",
    "    images_= os.listdir()\n",
    "    for img_ in images_:\n",
    "        \n",
    "        # split image number and name\n",
    "        num = img_.split('_')[0]\n",
    "        name = img_.split('_')[1][:-4]\n",
    "            \n",
    "        # load image\n",
    "        image_ = cv2.imread(img_)\n",
    "        img_rgb = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # detect face\n",
    "        image_ = face_detector.detect_faces(img_rgb)\n",
    "        if image_:\n",
    "            res = max(image_, key=lambda b: b['box'][2] * b['box'][3])\n",
    "            face, _, _ = get_face(img_rgb, res['box'])\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "\n",
    "        # add images array to images list\n",
    "        test_images.append(face)\n",
    "    \n",
    "        # images_count = images_count + 1\n",
    "        images_count += 1\n",
    "\n",
    "        test_labels.append([class_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test images: 140, train images: 420, names: 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"test images: {len(test_images)}, train images: {len(train_images)}, names: {len(class_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 224, 224, 3) (140, 224, 224, 3) (420, 28) (140, 28)\n"
     ]
    }
   ],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_images = np.array(train_images).astype('float32')/255\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_images = np.array(test_images).astype('float32')/255\n",
    "\n",
    "test_labels = utils.to_categorical(test_labels)\n",
    "train_labels = utils.to_categorical(train_labels)\n",
    "\n",
    "train_images, train_labels = shuffle(train_images, train_labels)\n",
    "test_images, test_labels = shuffle(test_images, test_labels)\n",
    "\n",
    "print(train_images.shape, test_images.shape, train_labels.shape, test_labels.shape)\n",
    "np.savez_compressed(r\"F:\\ai\\recognition-football-players\\dataset\", train_images=train_images, test_images=test_images, train_labels=train_labels, test_labels=test_labels, names=class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2c5f25bb9ed415c713469b698bd1c5102b92e6a1216299b5adc124b9cd965a4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
